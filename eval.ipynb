{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tqdm\n",
    "# !pip install --upgrade ta\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install torch\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 year -> 1 year\n",
    "config = {\n",
    "    \"shift_day\":1,\n",
    "    \"test_size\":0.2,\n",
    "    \"random_seed\":1,\n",
    "    \"window_size\":10,\n",
    "    \"shuffle_dataset\":True,\n",
    "    \"test_start_idx\":None,\n",
    "    \"batch_size\":32,\n",
    "    \"learning_rate\":0.001,\n",
    "    'min_date': \"2015-01-01\",\n",
    "    'max_date': \"2019-12-31\",\n",
    "    \"output_size\":1,\n",
    "    'input_size':88,\n",
    "    \"epoch_nums\": 201,\n",
    "    'lstm_hidden_size':16,\n",
    "    'attn_embed_dim':64,\n",
    "    'attn_num_heads':1,\n",
    "    \"model\": \"LSTM\",\n",
    "    # \"model\": \"ATTN\",\n",
    "    # \"model\": \"CNNLSTM\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ta import add_all_ta_features\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from models import LSTM, ATTN\n",
    "# from models import LSTM, ATTN, CNNLSTM\n",
    "from utils import process\n",
    "\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function & Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitArrayAccordSliceWindow(\n",
    "    array: Annotated[np.ndarray, \"features data shape:[times, feats]\"],\n",
    "    window_size: Annotated[int, \"window's size\"],\n",
    "    num_predict: Annotated[int, \"number of prediction >= 1\"] = 1,\n",
    ") -> Annotated[Tuple[np.ndarray, np.ndarray], \"(X, y)\"]:\n",
    "    l = array.shape[0]\n",
    "    X, Y = [], []\n",
    "    for i in range(0, l - window_size + 1 - num_predict):\n",
    "        x = array[i:(i + window_size)]\n",
    "        y = array[(i + window_size):(i + window_size + num_predict)]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return np.stack(X, axis=0), np.stack(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StocksDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: Annotated[torch.Tensor, \"shape: [batch, times, feats]\"],\n",
    "        Y: Annotated[torch.Tensor, \"shape: [batch, num_predict, feats]\"],\n",
    "        DATE_X: Annotated[torch.Tensor, \"shape: [batch, times]\"] = None,\n",
    "        DATE_Y: Annotated[torch.Tensor, \"shape: [batch, num_predict]\"] = None,\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.n_samples = X.shape[0]\n",
    "        self.DATE_X = DATE_X\n",
    "        self.DATE_Y = DATE_Y\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "    def get(self, index: int):\n",
    "        if self.DATE_X is not None and self.DATE_Y is not None:\n",
    "            return self.X[index], self.Y[index], self.DATE_X[index], self.DATE_Y[index]\n",
    "\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "def getTrainTestDataIndices(\n",
    "    dataset: Annotated[StocksDataset, \"dataset\"],\n",
    "    split_config: Annotated[Dict[str, Any], \"dict of config\"] = {\n",
    "        \"test_size\": 0.2,\n",
    "        \"shuffle_dataset\": True,\n",
    "        \"random_seed\": 1,\n",
    "        \"test_start_idx\": None\n",
    "    },\n",
    ") -> Tuple[List[int], List[int]]:\n",
    "\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor((1.0 - split_config[\"test_size\"]) * dataset_size))\n",
    "    if \"test_start_idx\" in split_config and split_config[\"test_start_idx\"] is not None:\n",
    "        split = split_config[\"test_start_idx\"]\n",
    "\n",
    "    train_indices, test_indices = indices[:split], indices[split:]\n",
    "    if split_config[\"shuffle_dataset\"]:\n",
    "        np.random.seed(split_config[\"random_seed\"])\n",
    "        np.random.shuffle(train_indices)\n",
    "\n",
    "    return train_indices, test_indices\n",
    "\n",
    "\n",
    "def getTrainTestDataSampler(\n",
    "    dataset: Annotated[StocksDataset, \"dataset\"],\n",
    "    split_config: Annotated[Dict[str, Any], \"dict of config\"] = {\n",
    "        \"test_size\": 0.2,\n",
    "        \"shuffle_dataset\": True,\n",
    "        \"random_seed\": 1,\n",
    "        \"test_start_idx\": None\n",
    "    },\n",
    ") -> Tuple[\n",
    "        Annotated[np.ndarray, \"indices of training data\"],\n",
    "        Annotated[np.ndarray, \"indices of testing data\"],\n",
    "        Annotated[SubsetRandomSampler, \"sampler of training data\"],\n",
    "        Annotated[SubsetRandomSampler, \"sampler of testing data\"]]:\n",
    "\n",
    "    train_indices, test_indices = getTrainTestDataIndices(\n",
    "        dataset, split_config)\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "    return train_indices, test_indices, train_sampler, test_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(\"./data/台指期2001_2019_1分K/all.csv\"):\n",
    "    df = pd.read_csv(\"./data/台指期2001_2019_1分K/all.csv\")\n",
    "else:\n",
    "    file_paths = os.listdir(\"./data/台指期2001_2019_1分K\")\n",
    "    file_paths = sorted([f for f in file_paths if f[-4:] == '.zip'])\n",
    "\n",
    "    col_names = [\"0\", \"1\", \"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "    data_list = []\n",
    "    for file_path in tqdm(file_paths):\n",
    "        data_list.append(pd.read_csv(f\"./data/台指期2001_2019_1分K/{file_path}\", names=col_names))\n",
    "    data_df = pd.concat(data_list).reset_index(drop=True)\n",
    "\n",
    "    df = add_all_ta_features(\n",
    "        df=data_df,\n",
    "        open=\"Open\",\n",
    "        high=\"High\",\n",
    "        low=\"Low\",\n",
    "        close=\"Close\",\n",
    "        volume=\"Volume\",\n",
    "    )\n",
    "    df.to_csv(\"./data/台指期2001_2019_1分K/all.csv\", index=False)\n",
    "df = df[df.Date >= config[\"min_date\"]]\n",
    "df = df[df.Date <= config[\"max_date\"]]\n",
    "df.ffill(inplace=True)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['predClose'] = df[\"Close\"].shift(config[\"shift_day\"])\n",
    "df = df.loc[config[\"shift_day\"]:,:].reset_index(drop=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_columns = [\n",
    "    'Open', 'High', 'Low', 'Close', 'predClose','Volume',\n",
    "    'volume_adi', 'volume_obv', 'volume_cmf', 'volume_fi', 'volume_em',\n",
    "    'volume_sma_em', 'volume_vpt', 'volume_vwap', 'volume_mfi',\n",
    "    'volume_nvi', 'volatility_bbm', 'volatility_bbh', 'volatility_bbl',\n",
    "    'volatility_bbw', 'volatility_bbp', 'volatility_bbhi',\n",
    "    'volatility_bbli', 'volatility_kcc', 'volatility_kch', 'volatility_kcl',\n",
    "    'volatility_kcw', \n",
    "    # 'volatility_kcp', \n",
    "    'volatility_kchi',\n",
    "    'volatility_kcli', 'volatility_dcl', 'volatility_dch', 'volatility_dcm',\n",
    "    'volatility_dcw', 'volatility_dcp', 'volatility_atr', 'volatility_ui',\n",
    "    'trend_macd', 'trend_macd_signal', 'trend_macd_diff', 'trend_sma_fast',\n",
    "    'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow',\n",
    "    # 'trend_vortex_ind_pos',\n",
    "    # 'trend_vortex_ind_neg',\n",
    "    'trend_vortex_ind_diff',\n",
    "    'trend_trix', 'trend_mass_index', 'trend_dpo', 'trend_kst',\n",
    "    'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
    "    'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
    "    'trend_stc', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_cci',\n",
    "    'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
    "    'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
    "    'trend_psar_down', 'trend_psar_up_indicator',\n",
    "    'trend_psar_down_indicator', 'momentum_rsi', 'momentum_stoch_rsi',\n",
    "    'momentum_stoch_rsi_k', 'momentum_stoch_rsi_d', 'momentum_tsi',\n",
    "    'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr',\n",
    "    'momentum_ao', 'momentum_roc', 'momentum_ppo', 'momentum_ppo_signal',\n",
    "    'momentum_ppo_hist', 'momentum_pvo', 'momentum_pvo_signal',\n",
    "    'momentum_pvo_hist', 'momentum_kama',\n",
    "    'others_dr', 'others_dlr', 'others_cr',\n",
    "]\n",
    "len(feat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_point = int(len(df) * (1 - config[\"test_size\"]))\n",
    "scaler.fit(df.loc[:train_set_point, feat_columns]) # 對所有特徵\n",
    "y_scaler.fit(df.loc[:train_set_point, [\"Close\"]]) # 對收盤價\n",
    "scaled_arr = scaler.transform(df.loc[:, feat_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = splitArrayAccordSliceWindow(array=scaled_arr, window_size=config[\"window_size\"])\n",
    "Date_X, Date_Y = splitArrayAccordSliceWindow(array=df[\"Date\"].to_numpy(), window_size=config[\"window_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_index = feat_columns.index(\"predClose\")\n",
    "print(f\"response_index: {response_index}\")\n",
    "\n",
    "feat_indices = list(range(response_index)) + list(range(response_index+1, len(feat_columns)))\n",
    "\n",
    "X = X[:, :, feat_indices]\n",
    "Y = Y[:, :, response_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StocksDataset(X=X, Y=Y, DATE_X=Date_X, DATE_Y=Date_Y)\n",
    "\n",
    "dataset_utils = getTrainTestDataSampler(dataset=dataset, split_config=config)\n",
    "train_indices, test_indices, train_sampler, test_sampler = dataset_utils\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=config[\"batch_size\"], sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"model\"] == \"ATTN\":\n",
    "    model = ATTN.Model(config={\n",
    "        \"input_dim\":config[\"input_size\"],\n",
    "        \"embed_dim\":config[\"attn_embed_dim\"],\n",
    "        \"num_heads\":config[\"attn_num_heads\"],\n",
    "        \"output_size\":config[\"output_size\"],\n",
    "    })\n",
    "elif config[\"model\"] == \"LSTM\":\n",
    "    model = LSTM.Model(config={\n",
    "        'lstm_input_size':config[\"input_size\"],\n",
    "        'lstm_hidden_size':config[\"lstm_hidden_size\"],\n",
    "        'linear_output_size':config[\"output_size\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "runs_dir_path = \"./runs\"\n",
    "model_params_dir_path = \"./model_params\"\n",
    "exp_name = \"_\".join(\n",
    "        [\n",
    "            \"TX00\",\n",
    "            config[\"model\"],\n",
    "            f\"min_date-{config['min_date']}\",\n",
    "            f\"max_date-{config['max_date']}\",\n",
    "            f\"test_size-{config['test_size']}\",\n",
    "            f\"batch_size-{config['batch_size']}\"\n",
    "        ]\n",
    "    )\n",
    "folder_path = f\"{model_params_dir_path}/{exp_name}\"\n",
    "model.load_state_dict(torch.load(f\"{folder_path}/model_{epoch}.pth\").state_dict())\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train_idx = max(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "true_list = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(dataset):\n",
    "        x = torch.Tensor(x).unsqueeze(0).double()\n",
    "        y = torch.Tensor(y).unsqueeze(0).double()\n",
    "        out = model(x)\n",
    "        if out.shape != y.shape:\n",
    "            out = out.unsqueeze(-1)\n",
    "            out = out.float()\n",
    "            labels = labels.float()\n",
    "        pred_list.append(out)\n",
    "        true_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = torch.stack(pred_list)[:, 0, 0].numpy()\n",
    "true_list = torch.stack(true_list)[:, 0, 0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = torch.stack(pred_list).numpy()\n",
    "# true_list = torch.stack(true_list)[:, 0, 0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset.DATE_Y, pred_list, label=\"prediction\")\n",
    "plt.plot(dataset.DATE_Y, true_list, label=\"true\")\n",
    "plt.legend()\n",
    "plt.axvline(x=dataset.DATE_Y[max_train_idx])\n",
    "plt.title(\"Scaled Close Value (true v.s. pred)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset.DATE_Y, y_scaler.inverse_transform(true_list.reshape(-1, 1)).reshape(-1), label=\"true\")\n",
    "plt.plot(dataset.DATE_Y, y_scaler.inverse_transform(pred_list.reshape(-1, 1)).reshape(-1), label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.axvline(x=dataset.DATE_Y[max_train_idx])\n",
    "plt.title(\"Origin scale Close Value (true v.s. pred)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_dir_path = \"PredictTXPrice/plot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_train_indices = list(sorted(train_indices))\n",
    "plt.plot(dataset.DATE_Y[sorted_train_indices], y_scaler.inverse_transform(true_list.reshape(-1, 1)).reshape(-1)[sorted_train_indices], label=\"true\")\n",
    "plt.plot(dataset.DATE_Y[sorted_train_indices], y_scaler.inverse_transform(pred_list.reshape(-1, 1)).reshape(-1)[sorted_train_indices], label=\"prediction\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.title(\"Origin scale Close Value for Training Dataset (true v.s. pred)\")\n",
    "plt.savefig(plt_dir_path + exp_name + f\"_epoch{epoch}_Origin_scale_Training_Dataset.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset.DATE_Y[test_indices], y_scaler.inverse_transform(true_list.reshape(-1, 1)).reshape(-1)[test_indices], label=\"true\")\n",
    "plt.plot(dataset.DATE_Y[test_indices], y_scaler.inverse_transform(pred_list.reshape(-1, 1)).reshape(-1)[test_indices], label=\"prediction\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.title(\"Origin scale Close Value for Testing Dataset (true v.s. pred)\")\n",
    "plt.savefig(plt_dir_path + exp_name + f\"_epoch{epoch}_Origin_scale_Testing_Dataset.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 ('venv_PredictTXPrice': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8370313d6f0b7f430a5932d7f3a925a41c7861c4de7bec1ba3dab10983916d8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
